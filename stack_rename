#!/usr/bin/env python3
import json
import os
import stat
import time
from libs import command_parser, command_checker, custom_logger, file_handler, aws_handler
from cfn_flip import to_json
from pprint import pprint

__version__ = '0.1'


def detect_drift(aws_client, stack_id):
    stack_drift_id = aws_client.cfn_drift_detect_id(stack_id)
    stack_drift_status = aws_client.cfn_drift_detect_status(stack_drift_id)
    resource_drifts = []

    while stack_drift_status['DetectionStatus'] == "DETECTION_IN_PROGRESS":
        time.sleep(5)
        stack_drift_status = aws_client.cfn_drift_detect_status(stack_drift_id)

    if stack_drift_status['DetectionStatus'] != "DETECTION_COMPLETE" or stack_drift_status[
        'StackDriftStatus'] != "DRIFTED":
        if stack_drift_status['StackDriftStatus'] != "IN_SYNC":
            logging.error("Could not determine drift results")
            raise ValueError("Drift Results Undetermined")

    resource_drifts_result = aws_client.cfn_stack_resource_drifts(stack_id)
    resource_drifts.extend(resource_drifts_result['StackResourceDrifts'])

    while 'NextToken' in resource_drifts_result:
        token = resource_drifts_result['NextToken']
        resource_drifts_result = aws_client.cfn_stack_resource_drifts(stack_id, next_token=token)
        resource_drifts.extend(resource_drifts_result['StackResourceDrifts'])

    return resource_drifts


def sanitize_template(template, desc_stack_resources, resource_drifts):
    support_import_list = list()
    non_importable_list = list()
    found = False
    resource_exists = False
    resource_identifiers = config_data['cloudformation']['resource_identifiers']

    for k, v in template['Resources'].items():
        for deployed_resource in desc_stack_resources:
            if k == deployed_resource['LogicalResourceId']:
                resource_exists = True

        if not resource_exists and 'Condition' in template['Resources'][k]:  # skip conditionals
            continue

        for i in range(len(resource_drifts)):
            if resource_drifts[i]['LogicalResourceId'] == k:
                found = True
                support_import_list.append(k)
                break
        if not found:
            logging.warning(f'Found resource: {k} type without drift info: {template["Resources"][k]["Type"]}: '
                            f'This resource will need to be recreated')
            non_importable_list.append(k)
        if template['Resources'][k]['Type'] not in resource_identifiers.keys():
            logging.warning(f'Found non-importable resource: {k} type: {template["Resources"][k]["Type"]}: '
                            f'This resource will need to be recreated')
        return support_import_list, non_importable_list


def set_resource_retention(template, supported_resources):
    for resource in supported_resources:
        template['Resources'][resource]['DeletionPolicy'] = 'Retain'
        logging.info(f'Added Retain Deletion Policy to resource: {resource}')

    logging.info(f'Added Retain Policy to all supported resources: Updating Stack Now')
    return template




def main():
    aws_client = aws_handler.AWS(data=config_data)
    stack_name = options.stack_name
    new_stack_name = options.new_stack

    aws_client.login()
    aws_client.cfn_client()
    stack_desc = aws_client.cfn_describe_stack(stack_name=stack_name)
    new_stack_desc = aws_client.cfn_describe_stack(stack_name=new_stack_name)
    stack_id = stack_desc['StackId']
    current_stack_template = aws_client.cfn_get_template(stack_id=stack_id)
    stack_params = []
    if 'Parameters' in stack_desc:
        stack_params = stack_desc['Parameters']

    if not stack_desc:
        logging.error(f'stack: {stack_name} does not exist aborting')
        raise ValueError(f'Error {stack_name} does not exist')

    if new_stack_desc:
        logging.error(f'stack: {new_stack_name} already exists aborting')
        raise ValueError(f'Error {new_stack_name} already exists')

    # Convert template from ordered dict to normal python dict
    if not isinstance(current_stack_template, str):
        current_stack_template = json.dumps(dict(current_stack_template))

    stack_template = json.loads(to_json(current_stack_template))

    desc_stack_resources = aws_client.cfn_describe_resources(stack_id)
    resource_drifts = detect_drift(aws_client, stack_id)
    supported_resources, unsupported_resources = sanitize_template(stack_template,
                                                                   desc_stack_resources,
                                                                   resource_drifts)

    retain_template = set_resource_retention(template=stack_template,
                                             supported_resources=supported_resources)

    pprint(stack_desc)
    pprint(stack_template)

    # all resources that cant be imported - we need to list them and say they will be deleted
    # we wont bother importing / exporting them - simplest solution we feed back the original template to the new stack
    # which will rebuild everything as we are already deleting the old stack anyway - anything that can be preserved
    # will be, anything that cant is recreated in the new stack.

    # we need to get the exports and we need to find all stacks importing those exports
    # to force them to import the actual value, rather than the import name
    # finally once everything is moved across we need to update the same stacks
    # to use the new stack_name if the export includes the stack_name and update them to this setting - or should we ?
    # cfn may not be able to recognise the change made here - actually it should do if we use the cloudformation stack
    # change mechanism - the only thing to do then is to the list the changes to the user once done as they will need to
    # update their templates in the associated repos manually afterwards with whatever the new import varibles are now.


if __name__ == "__main__":
    name = 'stack_rename'
    # initialise the command line checker, add in all of the options
    cmd_opts = command_parser.Commands(name=name, version=__version__)
    cmd_opts.add_config()
    cmd_opts.add_aws_auth()
    cmd_opts.add_aws_config()
    cmd_opts.add_cloudformation()
    options, arg_parser = cmd_opts.set_options()
    # set up the logging
    logging = custom_logger.colourLog(name=name, config_file=options.config)
    # set up the io handling
    io_handle = file_handler.FileHandler()
    # initialise the config data
    config_data = io_handle.read_file(options.config)
    # parse through the provided options make sure everything is set as required
    # also do init sanity checks and config fixes/population
    cmd_check = command_checker.CommandCheck(options=options, parser=arg_parser, config_data=config_data)
    cmd_check.aws()
    main()
